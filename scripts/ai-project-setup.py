#!/usr/bin/env python3
"""
Setup Automatizado de Projetos de IA - AR Online
Cria estrutura padrÃ£o para novos projetos de ML
"""
import os
import json
import argparse
from datetime import datetime
from pathlib import Path

class AIProjectSetup:
    """Setup automatizado para projetos de IA"""
    
    def __init__(self, project_name: str, project_type: str = "classification"):
        self.project_name = project_name
        self.project_type = project_type
        self.project_dir = Path(project_name)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def create_project_structure(self):
        """Criar estrutura de diretÃ³rios do projeto"""
        print(f"Criando estrutura do projeto: {self.project_name}")
        
        # DiretÃ³rios principais
        directories = [
            "data/raw",
            "data/processed", 
            "data/external",
            "models",
            "notebooks",
            "scripts",
            "docs",
            "tests",
            "experiments",
            "logs",
            "reports",
            "templates"
        ]
        
        for directory in directories:
            dir_path = self.project_dir / directory
            dir_path.mkdir(parents=True, exist_ok=True)
            print(f"  âœ… Criado: {directory}")
        
        # Criar arquivos .gitkeep para diretÃ³rios vazios
        gitkeep_dirs = ["data/raw", "data/processed", "data/external", "logs", "reports"]
        for directory in gitkeep_dirs:
            gitkeep_path = self.project_dir / directory / ".gitkeep"
            gitkeep_path.touch()
    
    def create_config_files(self):
        """Criar arquivos de configuraÃ§Ã£o"""
        print("Criando arquivos de configuraÃ§Ã£o...")
        
        # project_config.json
        project_config = {
            "project_name": self.project_name,
            "project_type": self.project_type,
            "created_date": datetime.now().isoformat(),
            "version": "1.0.0",
            "objectives": {
                "business_goal": "A ser definido",
                "success_metrics": ["accuracy", "precision", "recall", "f1"],
                "target_performance": 0.8
            },
            "timeline": {
                "start_date": datetime.now().strftime("%Y-%m-%d"),
                "end_date": "A ser definido",
                "milestones": []
            },
            "compliance": {
                "lgpd_compliant": True,
                "data_retention_policy": "2_years",
                "audit_trail": True,
                "personal_data_mapping": {},
                "legal_basis": "A ser definido"
            },
            "quality_gates": {
                "min_accuracy": 0.8,
                "min_data_quality": 0.7,
                "required_tests": ["unit", "integration", "performance"],
                "audit_threshold": 80
            },
            "data": {
                "sources": [],
                "quality_threshold": 0.7,
                "preprocessing_steps": []
            },
            "model": {
                "type": self.project_type,
                "hyperparameter_tuning": True,
                "cross_validation": True,
                "interpretability_required": True
            },
            "deployment": {
                "environment": "production",
                "monitoring": True,
                "versioning": True,
                "rollback_plan": True
            }
        }
        
        config_path = self.project_dir / "project_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(project_config, f, indent=2, ensure_ascii=False)
        print(f"  âœ… Criado: project_config.json")
        
        # requirements.txt
        requirements = [
            "pandas>=1.5.0",
            "numpy>=1.21.0",
            "scikit-learn>=1.1.0",
            "matplotlib>=3.5.0",
            "seaborn>=0.11.0",
            "jupyter>=1.0.0",
            "joblib>=1.2.0",
            "shap>=0.41.0",
            "pytest>=7.0.0",
            "black>=22.0.0",
            "flake8>=5.0.0"
        ]
        
        req_path = self.project_dir / "requirements.txt"
        with open(req_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(requirements))
        print(f"  âœ… Criado: requirements.txt")
        
        # .gitignore
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Jupyter Notebook
.ipynb_checkpoints

# Environment
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Data
data/raw/*
!data/raw/.gitkeep
data/processed/*
!data/processed/.gitkeep
data/external/*
!data/external/.gitkeep

# Models
models/*.joblib
models/*.pkl
models/*.h5

# Logs
logs/*
!logs/.gitkeep

# Reports
reports/*
!reports/.gitkeep

# Experiments
experiments/*/
!experiments/.gitkeep

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Temporary files
*.tmp
*.temp
"""
        
        gitignore_path = self.project_dir / ".gitignore"
        with open(gitignore_path, 'w', encoding='utf-8') as f:
            f.write(gitignore_content)
        print(f"  âœ… Criado: .gitignore")
    
    def create_template_files(self):
        """Criar arquivos template"""
        print("Criando arquivos template...")
        
        # README.md
        readme_content = f"""# {self.project_name}

## ğŸ“‹ DescriÃ§Ã£o do Projeto
[Descrever objetivo de negÃ³cio e problema a ser resolvido]

## ğŸ¯ Objetivos
- **Objetivo Principal**: [Definir objetivo principal]
- **MÃ©tricas de Sucesso**: [Listar mÃ©tricas]
- **Performance Alvo**: [Definir threshold mÃ­nimo]

## ğŸ“Š Dados
- **Fonte**: [Descrever fonte dos dados]
- **Volume**: [Quantidade de registros]
- **PerÃ­odo**: [PerÃ­odo dos dados]
- **Qualidade**: [Score de qualidade dos dados]

## ğŸ¤– Modelo
- **Tipo**: {self.project_type}
- **Algoritmo**: [Algoritmo escolhido]
- **Performance**: [MÃ©tricas de performance]

## ğŸ“ Estrutura do Projeto
```
{self.project_name}/
â”œâ”€â”€ data/                    # Dados do projeto
â”‚   â”œâ”€â”€ raw/                 # Dados brutos
â”‚   â”œâ”€â”€ processed/           # Dados processados
â”‚   â””â”€â”€ external/            # Dados externos
â”œâ”€â”€ models/                  # Modelos treinados
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”œâ”€â”€ scripts/                 # Scripts Python
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o
â”œâ”€â”€ tests/                   # Testes automatizados
â”œâ”€â”€ experiments/             # Experimentos
â”œâ”€â”€ logs/                    # Logs de execuÃ§Ã£o
â”œâ”€â”€ reports/                 # RelatÃ³rios
â””â”€â”€ templates/               # Templates
```

## ğŸš€ Como Executar

### 1. ConfiguraÃ§Ã£o Inicial
```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar ambiente
python scripts/setup_environment.py
```

### 2. AnÃ¡lise de Dados
```bash
# Executar anÃ¡lise
jupyter notebook notebooks/01_data_analysis.ipynb
```

### 3. Treinamento
```bash
# Treinar modelo
python scripts/train_model.py
```

### 4. AvaliaÃ§Ã£o
```bash
# Executar testes
python -m pytest tests/

# Executar auditoria
python scripts/ai-training-auditor.py
```

## ğŸ“‹ Checklist de Qualidade
- [ ] Dados analisados e documentados
- [ ] Modelo treinado com validaÃ§Ã£o cruzada
- [ ] Testes automatizados implementados
- [ ] Auditoria executada e aprovada
- [ ] DocumentaÃ§Ã£o completa
- [ ] Compliance LGPD validado

## ğŸ“ Contato
- **ResponsÃ¡vel**: [Nome do responsÃ¡vel]
- **Email**: [email@ar-online.com.br]
- **Data de CriaÃ§Ã£o**: {datetime.now().strftime('%Y-%m-%d')}

---
*Projeto criado seguindo os padrÃµes de qualidade da AR Online*
"""
        
        readme_path = self.project_dir / "README.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        print(f"  âœ… Criado: README.md")
        
        # Template de anÃ¡lise de dados
        analysis_template = """# AnÃ¡lise de Dados - {project_name}

## ğŸ“Š Objetivo
[Descrever objetivo da anÃ¡lise]

## ğŸ“‹ Checklist de AnÃ¡lise
- [ ] Carregamento dos dados
- [ ] AnÃ¡lise exploratÃ³ria bÃ¡sica
- [ ] VerificaÃ§Ã£o de qualidade
- [ ] AnÃ¡lise de vieses
- [ ] IdentificaÃ§Ã£o de padrÃµes
- [ ] DocumentaÃ§Ã£o de insights

## ğŸ” AnÃ¡lise ExploratÃ³ria

### 1. Carregamento dos Dados
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Carregar dados
data = pd.read_csv('data/raw/dataset.csv')

# InformaÃ§Ãµes bÃ¡sicas
print(f"Shape: {{data.shape}}")
print(f"Columns: {{list(data.columns)}}")
print(f"Data types: {{data.dtypes}}")
```

### 2. AnÃ¡lise de Qualidade
```python
# Valores ausentes
missing_data = data.isnull().sum()
print("Valores ausentes:")
print(missing_data[missing_data > 0])

# Duplicatas
duplicates = data.duplicated().sum()
print(f"Duplicatas: {{duplicates}}")

# Outliers
numeric_cols = data.select_dtypes(include=[np.number]).columns
for col in numeric_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = data[(data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)]
    print(f"{{col}}: {{len(outliers)}} outliers")
```

### 3. AnÃ¡lise de DistribuiÃ§Ãµes
```python
# DistribuiÃ§Ã£o das variÃ¡veis numÃ©ricas
data[numeric_cols].hist(bins=50, figsize=(15, 10))
plt.tight_layout()
plt.show()

# CorrelaÃ§Ãµes
correlation_matrix = data[numeric_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de CorrelaÃ§Ã£o')
plt.show()
```

## ğŸ“ˆ Insights e PrÃ³ximos Passos
[Documentar insights encontrados e prÃ³ximos passos]

---
*AnÃ¡lise executada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
""".format(project_name=self.project_name)
        
        analysis_path = self.project_dir / "notebooks" / "01_data_analysis.ipynb"
        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.write(analysis_template)
        print(f"  âœ… Criado: notebooks/01_data_analysis.ipynb")
        
        # Template de treinamento
        training_template = """#!/usr/bin/env python3
\"\"\"
Treinamento de Modelo - {project_name}
\"\"\"
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib
import json
from datetime import datetime

class ModelTrainer:
    \"\"\"Treinador de modelo para {project_name}\"\"\"
    
    def __init__(self):
        self.model = None
        self.best_params = {{}}
        self.training_log = []
    
    def load_data(self, data_path):
        \"\"\"Carregar dados processados\"\"\"
        data = pd.read_csv(data_path)
        print(f"Dados carregados: {{data.shape}}")
        return data
    
    def prepare_features(self, data, target_column):
        \"\"\"Preparar features para treinamento\"\"\"
        X = data.drop(columns=[target_column])
        y = data[target_column]
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        return X_train, X_test, y_train, y_test
    
    def train_model(self, X_train, y_train):
        \"\"\"Treinar modelo com validaÃ§Ã£o cruzada\"\"\"
        # ConfiguraÃ§Ã£o de hiperparÃ¢metros
        param_grid = {{
            'n_estimators': [100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5],
            'min_samples_leaf': [1, 2]
        }}
        
        # Grid Search
        rf = RandomForestClassifier(random_state=42)
        grid_search = GridSearchCV(
            rf, param_grid, cv=5, scoring='f1_weighted', 
            n_jobs=-1, verbose=1
        )
        
        # Treinar
        grid_search.fit(X_train, y_train)
        
        self.model = grid_search.best_estimator_
        self.best_params = grid_search.best_params_
        
        print(f"Melhores parÃ¢metros: {{self.best_params}}")
        print(f"Melhor score CV: {{grid_search.best_score_:.3f}}")
        
        return self.model
    
    def evaluate_model(self, X_test, y_test):
        \"\"\"Avaliar modelo\"\"\"
        y_pred = self.model.predict(X_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)
        
        print(f"Accuracy: {{accuracy:.3f}}")
        print("Classification Report:")
        print(report)
        
        return {{
            'accuracy': accuracy,
            'classification_report': report
        }}
    
    def save_model(self, output_path='models/final_model.joblib'):
        \"\"\"Salvar modelo treinado\"\"\"
        joblib.dump(self.model, output_path)
        
        # Salvar configuraÃ§Ã£o
        config = {{
            'best_params': self.best_params,
            'training_date': datetime.now().isoformat(),
            'model_type': 'RandomForestClassifier'
        }}
        
        with open('models/model_config.json', 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"Modelo salvo: {{output_path}}")

def main():
    \"\"\"FunÃ§Ã£o principal\"\"\"
    print("Treinamento de Modelo - {project_name}")
    print("=" * 50)
    
    # Inicializar treinador
    trainer = ModelTrainer()
    
    # Carregar dados
    data = trainer.load_data('data/processed/processed_data.csv')
    
    # Preparar features
    X_train, X_test, y_train, y_test = trainer.prepare_features(data, 'target')
    
    # Treinar modelo
    model = trainer.train_model(X_train, y_train)
    
    # Avaliar modelo
    metrics = trainer.evaluate_model(X_test, y_test)
    
    # Salvar modelo
    trainer.save_model()
    
    print("\\nâœ… Treinamento concluÃ­do com sucesso!")

if __name__ == "__main__":
    main()
""".format(project_name=self.project_name)
        
        training_path = self.project_dir / "scripts" / "train_model.py"
        with open(training_path, 'w', encoding='utf-8') as f:
            f.write(training_template)
        print(f"  âœ… Criado: scripts/train_model.py")
        
        # Template de teste
        test_template = """#!/usr/bin/env python3
\"\"\"
Testes Automatizados - {project_name}
\"\"\"
import unittest
import pandas as pd
import numpy as np
import joblib
from sklearn.metrics import accuracy_score

class TestModelPerformance(unittest.TestCase):
    \"\"\"Testes de performance do modelo\"\"\"
    
    def setUp(self):
        \"\"\"Setup para testes\"\"\"
        # Carregar dados de teste
        self.test_data = pd.read_csv('data/processed/test_data.csv')
        
        # Carregar modelo
        try:
            self.model = joblib.load('models/final_model.joblib')
        except FileNotFoundError:
            self.skipTest("Modelo nÃ£o encontrado")
    
    def test_minimum_accuracy(self):
        \"\"\"Testar accuracy mÃ­nima\"\"\"
        X_test = self.test_data.drop(columns=['target'])
        y_test = self.test_data['target']
        
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        self.assertGreaterEqual(accuracy, 0.8, "Accuracy abaixo do threshold mÃ­nimo")
    
    def test_data_quality(self):
        \"\"\"Testar qualidade dos dados\"\"\"
        # Verificar valores ausentes
        missing_pct = self.test_data.isnull().sum().sum() / (self.test_data.shape[0] * self.test_data.shape[1])
        self.assertLess(missing_pct, 0.1, "Muitos valores ausentes")
        
        # Verificar duplicatas
        duplicate_pct = self.test_data.duplicated().sum() / len(self.test_data)
        self.assertLess(duplicate_pct, 0.05, "Muitas duplicatas")
    
    def test_model_stability(self):
        \"\"\"Testar estabilidade do modelo\"\"\"
        # Implementar teste de estabilidade conforme necessÃ¡rio
        self.assertTrue(True, "Teste de estabilidade")

if __name__ == '__main__':
    unittest.main()
"""
        
        test_path = self.project_dir / "tests" / "test_model_performance.py"
        with open(test_path, 'w', encoding='utf-8') as f:
            f.write(test_template)
        print(f"  âœ… Criado: tests/test_model_performance.py")
    
    def create_documentation(self):
        """Criar documentaÃ§Ã£o inicial"""
        print("Criando documentaÃ§Ã£o...")
        
        # DocumentaÃ§Ã£o de compliance
        compliance_doc = f"""# Compliance LGPD - {self.project_name}

## ğŸ“‹ Mapeamento de Dados Pessoais

### Dados Identificados
- [ ] Listar dados pessoais identificados
- [ ] Categorizar por tipo (identificaÃ§Ã£o, contato, etc.)
- [ ] Avaliar sensibilidade

### Base Legal
- [ ] Consentimento
- [ ] ExecuÃ§Ã£o de contrato
- [ ] ObrigaÃ§Ã£o legal
- [ ] Interesse pÃºblico
- [ ] Interesse legÃ­timo
- [ ] ProteÃ§Ã£o da vida

### PolÃ­ticas de RetenÃ§Ã£o
- **PerÃ­odo**: 2 anos
- **CritÃ©rios**: [Definir critÃ©rios]
- **Processo**: [Definir processo de exclusÃ£o]

## ğŸ”’ Medidas de SeguranÃ§a

### Controles TÃ©cnicos
- [ ] Criptografia de dados
- [ ] Controle de acesso
- [ ] Logs de auditoria
- [ ] Backup seguro

### Controles Organizacionais
- [ ] Treinamento da equipe
- [ ] PolÃ­ticas de acesso
- [ ] Procedimentos de incidente
- [ ] RevisÃ£o periÃ³dica

## ğŸ“Š RelatÃ³rio de Compliance
- **Status**: Em desenvolvimento
- **Ãšltima RevisÃ£o**: {datetime.now().strftime('%Y-%m-%d')}
- **PrÃ³xima RevisÃ£o**: [Definir data]

---
*Documento de compliance para {self.project_name}*
"""
        
        compliance_path = self.project_dir / "docs" / "compliance_lgpd.md"
        with open(compliance_path, 'w', encoding='utf-8') as f:
            f.write(compliance_doc)
        print(f"  âœ… Criado: docs/compliance_lgpd.md")
    
    def initialize_git_repository(self):
        """Inicializar repositÃ³rio Git"""
        print("Inicializando repositÃ³rio Git...")
        
        # Criar arquivo de configuraÃ§Ã£o Git
        git_config = f"""[core]
    repositoryformatversion = 0
    filemode = false
    bare = false
    logallrefupdates = true
    symlinks = false
    ignorecase = true

[remote "origin"]
    url = https://github.com/ar-online/{self.project_name}.git
    fetch = +refs/heads/*:refs/remotes/origin/*

[branch "main"]
    remote = origin
    merge = refs/heads/main
"""
        
        git_path = self.project_dir / ".git" / "config"
        git_path.parent.mkdir(parents=True, exist_ok=True)
        with open(git_path, 'w', encoding='utf-8') as f:
            f.write(git_config)
        
        print(f"  âœ… RepositÃ³rio Git inicializado")
    
    def generate_setup_summary(self):
        """Gerar resumo do setup"""
        summary = f"""
ğŸ‰ PROJETO {self.project_name.upper()} CRIADO COM SUCESSO!

ğŸ“ Estrutura Criada:
   â”œâ”€â”€ data/ (raw, processed, external)
   â”œâ”€â”€ models/
   â”œâ”€â”€ notebooks/
   â”œâ”€â”€ scripts/
   â”œâ”€â”€ docs/
   â”œâ”€â”€ tests/
   â”œâ”€â”€ experiments/
   â”œâ”€â”€ logs/
   â”œâ”€â”€ reports/
   â””â”€â”€ templates/

ğŸ“‹ Arquivos de ConfiguraÃ§Ã£o:
   â”œâ”€â”€ project_config.json
   â”œâ”€â”€ requirements.txt
   â”œâ”€â”€ .gitignore
   â””â”€â”€ README.md

ğŸ“š Templates Criados:
   â”œâ”€â”€ notebooks/01_data_analysis.ipynb
   â”œâ”€â”€ scripts/train_model.py
   â”œâ”€â”€ tests/test_model_performance.py
   â””â”€â”€ docs/compliance_lgpd.md

ğŸš€ PrÃ³ximos Passos:
   1. cd {self.project_name}
   2. pip install -r requirements.txt
   3. Configurar dados em data/raw/
   4. Executar anÃ¡lise em notebooks/
   5. Treinar modelo com scripts/
   6. Executar auditoria: python scripts/ai-training-auditor.py

ğŸ“ Suporte:
   - DocumentaÃ§Ã£o: docs/
   - Templates: templates/
   - PadrÃµes AR Online: [link para documentaÃ§Ã£o]

---
Projeto criado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        print(summary)
        
        # Salvar resumo
        summary_path = self.project_dir / "SETUP_SUMMARY.md"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary)
    
    def run_complete_setup(self):
        """Executar setup completo"""
        print(f"ğŸš€ Iniciando setup do projeto: {self.project_name}")
        print("=" * 60)
        
        try:
            # Criar estrutura
            self.create_project_structure()
            
            # Criar arquivos de configuraÃ§Ã£o
            self.create_config_files()
            
            # Criar templates
            self.create_template_files()
            
            # Criar documentaÃ§Ã£o
            self.create_documentation()
            
            # Inicializar Git
            self.initialize_git_repository()
            
            # Gerar resumo
            self.generate_setup_summary()
            
            print("\nâœ… Setup concluÃ­do com sucesso!")
            
        except Exception as e:
            print(f"\nâŒ Erro durante setup: {e}")
            raise

def main():
    """FunÃ§Ã£o principal"""
    parser = argparse.ArgumentParser(description='Setup automatizado de projetos de IA')
    parser.add_argument('--name', required=True, help='Nome do projeto')
    parser.add_argument('--type', default='classification', 
                       choices=['classification', 'regression', 'clustering'],
                       help='Tipo do projeto')
    
    args = parser.parse_args()
    
    # Executar setup
    setup = AIProjectSetup(args.name, args.type)
    setup.run_complete_setup()

if __name__ == "__main__":
    main()
